# Training
seed: 1
number_of_epochs: 100
batch_size: 128

optimizer:
  _target_: torch.optim.Adam
  lr: 0.0001
  weight_decay: 0.0

lr_scheduler:
  use_scheduler: False
  warmup_epochs: 5

device: cuda

# Wandb
wandb:
  project_name: smcn
  prefix: molhiv
  log: False

# Architecture
arch:
  # generic
  activation: relu
  residual: False
  embedding_dim: 64
  model_type: subcomplex
  number_cin_layers: 2
  number_subgraph_layers: 2
  output_ranks:  [0,1,2]
  number_of_mlp_layers: 2
  dropout: 0.5
  final_dropout: 0.5
  in_dropout: 0.0

  # ensemble subgraphs
  embedding_dim_cin: 64
  embedding_dim_subgraphs: 24
  residual_cin: False
  residual_subgraph: False
  dropout_cin: 0.2
  dropout_subgraph: 0.5
  output_ranks_subgraphs: [2]

# Dataset
dataset_root: datasets/subcomplex_molhiv
original_root: datasets/molhiv
num_workers: 4
construct_complexes: True
min_len: 3  # for cyclic lift
max_len:  6  # for cyclic lift
use_subcomplex_features:  True
subcomplex_low_rank:  0
subcomplex_high_rank:  2